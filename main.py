import asyncio
from openai import OpenAI
from aiogram import Bot, Dispatcher, types
from aiogram.filters import CommandStart
from aiogram.enums import ParseMode

# –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è
BOT_TOKEN = "7417545301:AAHqxallRESyfKIcVQNpELV6HqEaVCxfK1Q"
GROQ_API_KEY = "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"

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –∫–ª–∏–µ–Ω—Ç–∞ OpenAI —Å –ø–æ–¥–¥–µ—Ä–∂–∫–æ–π Groq
client = OpenAI(
    api_key=GROQ_API_KEY,
    base_url="https://api.groq.com/openai/v1"
)

bot = Bot(token=BOT_TOKEN, parse_mode=ParseMode.HTML)
dp = Dispatcher()

TRANSLATE_PROMPT = """
–¢—ã –ø—Ä–æ—Ñ–µ—Å—Å–∏–æ–Ω–∞–ª—å–Ω—ã–π –ø–µ—Ä–µ–≤–æ–¥—á–∏–∫-—Å–∏–Ω—Ö—Ä–æ–Ω–∏—Å—Ç, —Å–ø–µ—Ü–∏–∞–ª–∏–∑–∏—Ä—É—é—â–∏–π—Å—è –Ω–∞ –∫–æ–ª—É–º–±–∏–π—Å–∫–æ–º –∏—Å–ø–∞–Ω—Å–∫–æ–º.

–¢–≤–æ—è –∑–∞–¥–∞—á–∞ ‚Äî –ø–µ—Ä–µ–≤–æ–¥–∏—Ç—å –ª—é–±–æ–π —Ç–µ–∫—Å—Ç —Ç–∞–∫, —á—Ç–æ–±—ã –æ–Ω –∑–≤—É—á–∞–ª, –∫–∞–∫ —Ä–∞–∑–≥–æ–≤–æ—Ä–Ω–∞—è —Ä–µ—á—å –≤ –º–µ—Å—Å–µ–Ω–¥–∂–µ—Ä–∞—Ö.

üîí –ñ—ë—Å—Ç–∫–∏–µ –ø—Ä–∞–≤–∏–ª–∞:
1. –¢—ã –¢–û–õ–¨–ö–û –ø–µ—Ä–µ–≤–æ–¥–∏—à—å. –ù–ï –¥–∞—ë—à—å –ø–æ—è—Å–Ω–µ–Ω–∏–π, –ù–ï –≥–æ–≤–æ—Ä–∏—à—å –æ—Ç —Å–µ–±—è.
2. –ù–ò–ö–ê–ö–ò–• –∑–Ω–∞–∫–æ–≤ –ø—Ä–µ–ø–∏–Ω–∞–Ω–∏—è ‚Äî –∫—Ä–æ–º–µ –¥–≤—É—Ö:
   - –°—Ç–∞–≤–∏ `!` –≤ –∫–æ–Ω—Ü–µ —ç–º–æ—Ü–∏–æ–Ω–∞–ª—å–Ω—ã—Ö —Ñ—Ä–∞–∑ –∏–ª–∏ –∫–æ–º–∞–Ω–¥.
   - –°—Ç–∞–≤–∏ `?` –≤ –∫–æ–Ω—Ü–µ –≤–æ–ø—Ä–æ—Å–∏—Ç–µ–ª—å–Ω—ã—Ö —Ñ—Ä–∞–∑.
3. –ù–µ –∏—Å–ø–æ–ª—å–∑—É–π `¬°`, `¬ø`, —Ç–æ—á–∫–∏, –∑–∞–ø—è—Ç—ã–µ, –¥–≤–æ–µ—Ç–æ—á–∏—è –∏–ª–∏ —Ç–∏—Ä–µ ‚Äî –Ω–∏ –ø—Ä–∏ –∫–∞–∫–∏—Ö –æ–±—Å—Ç–æ—è—Ç–µ–ª—å—Å—Ç–≤–∞—Ö.
4. –ü–µ—Ä–µ–≤–æ–¥ –¥–æ–ª–∂–µ–Ω –∑–≤—É—á–∞—Ç—å –ø—Ä–æ—Å—Ç–æ, –∫–∞–∫ –±—É–¥—Ç–æ –¥–≤–∞ –∫–æ–ª—É–º–±–∏–π—Ü–∞ –æ–±—â–∞—é—Ç—Å—è –≤ —á–∞—Ç–µ.
5. –ï—Å–ª–∏ —Ç–µ–∫—Å—Ç —É–∂–µ –Ω–∞ –∏—Å–ø–∞–Ω—Å–∫–æ–º ‚Äî –≤–µ—Ä–Ω–∏ –µ–≥–æ –∫–∞–∫ –µ—Å—Ç—å, –Ω–∏—á–µ–≥–æ –Ω–µ –º–µ–Ω—è—è.

üìå –í–∞–∂–Ω–æ: –¢–´ –û–ë–Ø–ó–ê–ù –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å `!` –∏ `?` —Ç–∞–º, –≥–¥–µ —ç—Ç–æ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É–µ—Ç —Å–º—ã—Å–ª—É. –ù–∞–ø—Ä–∏–º–µ—Ä:
"–¢—ã –≥–¥–µ?" ‚Üí "donde estas?"
"–ë—ã—Å—Ç—Ä–æ —Å—é–¥–∞!" ‚Üí "ven ya!"
"–ß–µ–≥–æ —Ç–µ–±–µ?" ‚Üí "que quieres?"

–ò–≥–Ω–æ—Ä–∏—Ä–æ–≤–∞–Ω–∏–µ —ç—Ç–∏—Ö –¥–≤—É—Ö —Å–∏–º–≤–æ–ª–æ–≤ —Å—á–∏—Ç–∞–µ—Ç—Å—è –æ—à–∏–±–∫–æ–π.
"""


MAX_INPUT_TOKENS = 6000
MAX_OUTPUT_LENGTH = 4096

def split_text(text, max_length):
    chunks = []
    while text:
        if len(text) <= max_length:
            chunks.append(text)
            break

        split_at = max_length
        for marker in ['. ', '! ', '? ', '\n\n', '\n', ', ', ' ']:
            pos = text.rfind(marker, 0, max_length)
            if pos > 0:
                split_at = pos + len(marker)
                break

        chunk = text[:split_at].strip()
        chunks.append(chunk)
        text = text[split_at:].strip()
    return chunks

@dp.message()
async def translate_message(message: types.Message):
    original_text = message.text
    if not original_text.strip():
        return

    try:
        input_chunks = split_text(original_text, MAX_INPUT_TOKENS // 2)
        translations = []

        for chunk in input_chunks:
            response = client.chat.completions.create(
                model="llama3-70b-8192",
                messages=[
                    {"role": "system", "content": TRANSLATE_PROMPT},
                    {"role": "user", "content": chunk}
                ],
                temperature=0.1,
                max_tokens=MAX_INPUT_TOKENS
            )
            translation = response.choices[0].message.content.strip()
            translations.append(translation)

        full_translation = " ".join(translations)
        output_chunks = split_text(full_translation, MAX_OUTPUT_LENGTH)

        for i, chunk in enumerate(output_chunks):
            if i == 0:
                await message.reply(chunk)
            else:
                await bot.send_message(chat_id=message.chat.id, text=chunk)

    except Exception as e:
        print(f"Translation error: {e}")
        await message.reply("‚ùå Error de traducci√≥n. Int√©ntalo de nuevo.")

async def main():
    print("ü§ñ Traductor universal iniciado")
    await dp.start_polling(bot)

if __name__ == "__main__":
    asyncio.run(main())
