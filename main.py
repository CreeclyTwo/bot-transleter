import asyncio
import openai
from aiogram import Bot, Dispatcher, types

# –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è
BOT_TOKEN = "7417545301:AAHqxallRESyfKIcVQNpELV6HqEaVCxfK1Q"
GROQ_API_KEY = "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"

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ openai –¥–ª—è Groq
openai.api_key = GROQ_API_KEY
openai.api_base = "https://api.groq.com/openai/v1"

bot = Bot(token=BOT_TOKEN)
dp = Dispatcher()

TRANSLATE_PROMPT = """
–¢—ã - –ø—Ä–æ—Ñ–µ—Å—Å–∏–æ–Ω–∞–ª—å–Ω—ã–π –ø–µ—Ä–µ–≤–æ–¥—á–∏–∫-—Å–∏–Ω—Ö—Ä–æ–Ω–∏—Å—Ç. 
–¢–≤–æ—è –µ–¥–∏–Ω—Å—Ç–≤–µ–Ω–Ω–∞—è –∑–∞–¥–∞—á–∞ - –ø–µ—Ä–µ–≤–æ–¥–∏—Ç—å –õ–Æ–ë–û–ô –≤—Ö–æ–¥—è—â–∏–π —Ç–µ–∫—Å—Ç –Ω–∞ –∏—Å–ø–∞–Ω—Å–∫–∏–π —è–∑—ã–∫, —á—Ç–æ–±—ã –ø–æ–Ω–∏–º–∞–ª–∏ –∫–æ—Ä–µ–Ω–Ω—ã–µ –∂–∏—Ç–µ–ª–∏ –ö–æ–ª—É–º–±–∏–∏.
–ü—Ä–∞–≤–∏–ª–∞:
1. –ù–∏–∫–∞–∫–∏—Ö –ø–æ—è—Å–Ω–µ–Ω–∏–π, —Ç–æ–ª—å–∫–æ –ø–µ—Ä–µ–≤–æ–¥
2. –°–æ—Ö—Ä–∞–Ω—è–π –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—ã–π —Ç–æ–Ω (—Ñ–æ—Ä–º–∞–ª—å–Ω—ã–π/–Ω–µ—Ñ–æ—Ä–º–∞–ª—å–Ω—ã–π)
3. –ù–∏–∫–∞–∫–∏—Ö –ø—Ä–∏–≤–µ—Ç—Å—Ç–≤–∏–π –∏–ª–∏ –ø—Ä–æ—â–∞–Ω–∏–π
4. –ï—Å–ª–∏ —Ç–µ–∫—Å—Ç —É–∂–µ –Ω–∞ –∏—Å–ø–∞–Ω—Å–∫–æ–º - –≤–æ–∑–≤—Ä–∞—â–∞–π –µ–≥–æ –±–µ–∑ –∏–∑–º–µ–Ω–µ–Ω–∏–π
"""

MAX_INPUT_TOKENS = 6000
MAX_OUTPUT_LENGTH = 4096

def split_text(text, max_length):
    chunks = []
    while text:
        if len(text) <= max_length:
            chunks.append(text)
            break

        split_at = max_length
        for marker in ['. ', '! ', '? ', '\n\n', '\n', ', ', ' ']:
            pos = text.rfind(marker, 0, max_length)
            if pos > 0:
                split_at = pos + len(marker)
                break

        chunk = text[:split_at].strip()
        chunks.append(chunk)
        text = text[split_at:].strip()
    return chunks


@dp.message()
async def translate_message(message: types.Message):
    original_text = message.text
    if not original_text.strip():
        return

    try:
        input_chunks = split_text(original_text, MAX_INPUT_TOKENS // 2)
        translations = []

        for chunk in input_chunks:
            response = openai.ChatCompletion.create(
                model="llama3-70b-8192",
                messages=[
                    {"role": "system", "content": TRANSLATE_PROMPT},
                    {"role": "user", "content": chunk}
                ],
                temperature=0.1,
                max_tokens=MAX_INPUT_TOKENS
            )
            translation = response["choices"][0]["message"]["content"].strip()
            translations.append(translation)

        full_translation = " ".join(translations)
        output_chunks = split_text(full_translation, MAX_OUTPUT_LENGTH)

        for i, chunk in enumerate(output_chunks):
            if i == 0:
                await message.reply(chunk)
            else:
                await bot.send_message(chat_id=message.chat.id, text=chunk)

    except Exception as e:
        print(f"Translation error: {e}")
        await message.reply("‚ùå Error de traducci√≥n. Int√©ntalo de nuevo.")


async def main():
    print("ü§ñ Traductor universal iniciado")
    await dp.start_polling(bot)


if __name__ == "__main__":
    asyncio.run(main())
