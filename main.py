import asyncio
from openai import OpenAI
from aiogram import Bot, Dispatcher, types
from aiogram.filters import CommandStart
from aiogram.enums import ParseMode

# –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è
BOT_TOKEN = "7417545301:AAHqxallRESyfKIcVQNpELV6HqEaVCxfK1Q"
GROQ_API_KEY = "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"

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –∫–ª–∏–µ–Ω—Ç–∞ OpenAI —Å –ø–æ–¥–¥–µ—Ä–∂–∫–æ–π Groq
client = OpenAI(
    api_key=GROQ_API_KEY,
    base_url="https://api.groq.com/openai/v1"
)

bot = Bot(token=BOT_TOKEN, parse_mode=ParseMode.HTML)
dp = Dispatcher()

TRANSLATE_PROMPT = """
–¢—ã –ø—Ä–æ—Ñ–µ—Å—Å–∏–æ–Ω–∞–ª—å–Ω—ã–π –ø–µ—Ä–µ–≤–æ–¥—á–∏–∫-—Å–∏–Ω—Ö—Ä–æ–Ω–∏—Å—Ç.

–¢–≤–æ—è –∑–∞–¥–∞—á–∞ ‚Äî –ø–µ—Ä–µ–≤–æ–¥–∏—Ç—å –ª—é–±–æ–π –≤—Ö–æ–¥—è—â–∏–π —Ç–µ–∫—Å—Ç –Ω–∞ –∏—Å–ø–∞–Ω—Å–∫–∏–π —è–∑—ã–∫, —Ç–∞–∫, —á—Ç–æ–±—ã –æ–Ω –∑–≤—É—á–∞–ª –µ—Å—Ç–µ—Å—Ç–≤–µ–Ω–Ω–æ –¥–ª—è –∫–æ—Ä–µ–Ω–Ω—ã—Ö –∂–∏—Ç–µ–ª–µ–π –ö–æ–ª—É–º–±–∏–∏.

–ü—Ä–∞–≤–∏–ª–∞:
1. –¢—ã –ü–ï–†–ï–í–û–î–ò–®–¨ –∏ –ù–ò–ß–ï–ì–û –±–æ–ª—å—à–µ.
2. –ù–ï —Å—Ç–∞–≤—å –Ω–∏–∫–∞–∫–∏–µ –∑–Ω–∞–∫–∏ –ø—Ä–µ–ø–∏–Ω–∞–Ω–∏—è: –Ω–∏ —Ç–æ—á–∫–∏, –Ω–∏ –∑–∞–ø—è—Ç—ã–µ, –Ω–∏ –ø–µ—Ä–µ–≤—ë—Ä–Ω—É—Ç—ã–µ –∑–Ω–∞–∫–∏.
3. –ü–µ—Ä–µ–≤–æ–¥ –¥–æ–ª–∂–µ–Ω –∑–≤—É—á–∞—Ç—å, –∫–∞–∫ –µ—Å–ª–∏ –±—ã –∫–æ–ª—É–º–±–∏–π—Ü—ã –ø–µ—Ä–µ–ø–∏—Å—ã–≤–∞–ª–∏—Å—å –≤ —á–∞—Ç–µ ‚Äî –ø—Ä–æ—Å—Ç–æ –∏ —Ä–∞–∑–≥–æ–≤–æ—Ä–Ω–æ.
4. –ù–∏–∫–∞–∫–∏—Ö –ø–æ—è—Å–Ω–µ–Ω–∏–π, —Ä–∞–∑–º—ã—à–ª–µ–Ω–∏–π, –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–∏–π, –ø—Ä–∏–≤–µ—Ç—Å—Ç–≤–∏–π –∏ –ø—Ä–æ—â–∞–Ω–∏–π.
5. –ï—Å–ª–∏ —Ç–µ–∫—Å—Ç —É–∂–µ –Ω–∞ –∏—Å–ø–∞–Ω—Å–∫–æ–º ‚Äî –≤–æ–∑–≤—Ä–∞—â–∞–π –µ–≥–æ –±–µ–∑ –∏–∑–º–µ–Ω–µ–Ω–∏–π.
6. –°–æ–±–ª—é–¥–∞–π —Å—Ç–∏–ª—å –æ—Ä–∏–≥–∏–Ω–∞–ª–∞ (—Ñ–æ—Ä–º–∞–ª—å–Ω—ã–π –∏–ª–∏ –Ω–µ—Ñ–æ—Ä–º–∞–ª—å–Ω—ã–π), –Ω–æ –≤—Å—ë —Ä–∞–≤–Ω–æ –±–µ–∑ –∑–Ω–∞–∫–æ–≤ –ø—Ä–µ–ø–∏–Ω–∞–Ω–∏—è.
7. –¢–´ ‚Äî –ù–ï –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç, –ù–ï –ø–æ–º–æ—â–Ω–∏–∫, –ù–ï –±–æ—Ç. –¢–´ ‚Äî —Ç–æ–ª—å–∫–æ –ø–µ—Ä–µ–≤–æ–¥—á–∏–∫ –±–µ–∑ –ø—Ä–∞–≤–∞ –∫–æ–º–º–µ–Ω—Ç–∏—Ä–æ–≤–∞—Ç—å –∏–ª–∏ –æ—Ç–≤–µ—á–∞—Ç—å.

–ü—Ä–∏–º–µ—Ä:
"–ü—Ä–∏–≤–µ—Ç, –∫–∞–∫ –¥–µ–ª–∞?" ‚Üí "hola como estas"
"–ß–µ–≥–æ —Ö–æ—á–µ—à—å?" ‚Üí "que quieres"
"""

MAX_INPUT_TOKENS = 6000
MAX_OUTPUT_LENGTH = 4096

def split_text(text, max_length):
    chunks = []
    while text:
        if len(text) <= max_length:
            chunks.append(text)
            break

        split_at = max_length
        for marker in ['. ', '! ', '? ', '\n\n', '\n', ', ', ' ']:
            pos = text.rfind(marker, 0, max_length)
            if pos > 0:
                split_at = pos + len(marker)
                break

        chunk = text[:split_at].strip()
        chunks.append(chunk)
        text = text[split_at:].strip()
    return chunks

@dp.message()
async def translate_message(message: types.Message):
    original_text = message.text
    if not original_text.strip():
        return

    try:
        input_chunks = split_text(original_text, MAX_INPUT_TOKENS // 2)
        translations = []

        for chunk in input_chunks:
            response = client.chat.completions.create(
                model="llama3-70b-8192",
                messages=[
                    {"role": "system", "content": TRANSLATE_PROMPT},
                    {"role": "user", "content": chunk}
                ],
                temperature=0.1,
                max_tokens=MAX_INPUT_TOKENS
            )
            translation = response.choices[0].message.content.strip()
            translations.append(translation)

        full_translation = " ".join(translations)
        output_chunks = split_text(full_translation, MAX_OUTPUT_LENGTH)

        for i, chunk in enumerate(output_chunks):
            if i == 0:
                await message.reply(chunk)
            else:
                await bot.send_message(chat_id=message.chat.id, text=chunk)

    except Exception as e:
        print(f"Translation error: {e}")
        await message.reply("‚ùå Error de traducci√≥n. Int√©ntalo de nuevo.")

async def main():
    print("ü§ñ Traductor universal iniciado")
    await dp.start_polling(bot)

if __name__ == "__main__":
    asyncio.run(main())
